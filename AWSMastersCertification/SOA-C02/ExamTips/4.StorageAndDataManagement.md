# Exam TIPS<br>**Storage and Data Management

## S3 101
- **Object-based**<br>Object-based allows you to upload files
- **Not OS or DB Storage**<br>Not suitable to install an operating system or run a database on
- **Files Up to 5 TB**<br>Files can be from 0 bytes to 5 TB
- **Unlimeted Storage**<br>The total volumes of data and the number of objects you can store is unlimited

<br>

- Files Stored in buckets
- S3 is a universal namespace and all names have to be globaly unique
- Sample bucket URL: `https://<bucket_name>.s3.<region>.amazonaws.com/<key_name>`
  
<br><br><br>

## S3 Storage Classes
|Storage Class|Availability andDurability|AZ|Use Case|
|---|---|---|---|
|**S3 Standard**|99.99% Availability<br>11 9's Durability|>=3|Suitable for most workloads (e.g., websites, content distribution, mobile and gaming applications, and big data analytics)|
|**S3 Standard-Infrequent Access**|9.99% Availability<br>11 9's Durability|>=3|Long-term, infrequently accessed critical data (e.g., backups, data store for disaster recovery files, etc.). Minimum storage duration: 30|
|**S3 One Zone-Standard Access**|99.5% Availability<br>11 9's Durability|1|Long-term, infrequently accessed, non-critical data. Minimum storage duration: 30 days|
|**S3 Glacier Instant Retrieval**|99.9% Availability<br>11 9's Durability|>=3|Long-lived data, accessed approximately once per quarter with millisecond retrieval time. Minimum storage duration: 90 days|
|**S3 Glacier Flexible Retrieval**|99.99% Availability<br>11 9's Durability|>=3|Long-term data archiving that occasionally needs to be accessed within a few hours or minutes. Retrieval options of 1 minute to 12 hours. Minimum storage duration: 90 days|
|**S3 Glacier Deep Archive**|99.99% Availability<br>11 9's Durability|>=3|Rarely accessed data archiving with default retrieval time of 12 hours (e.g., financial records for regulatory purposes). Minimum storage duration: 180 davs|


<br><br><br>

## S3 Lifecycle Policy
- **Cost Effective**<br>Ensure you are using the most cost-effective option to store your objects in S3.
- **Creation Date**<br>
Lifecycle rules are based on object creation date.
- **Transition**<br>
Transition your objects to Infrequently Accessed Storage or to Glacier based on the rules you configure.
- **Housekeeping**<br>
You can also set an expiry date for objects you want S3 to delete after a certain time period has elapsed.

<br><br><br>

## Creating an S3 Bucket
- S3 buckets and objects do not allow public access
- If we want to enable public access, we need to explicitly configure it (disable block public access on the bucket and configure bucket policy allowing annonymous read)
- Use S3 to store any file type you can think of, e.g. photos, videos, code, documents and text files


<br><br><br>

## S3 Versioning Exam Tips
1. **Mutiple Versions**<br>Multiple versions of an object are stored in the same bucket
2. **DELETE Request**<br>Doesn't delete the objectm but applies a delete marker instead
3. **Protects Agains Accidental Deletion**<br>You can still access all the previous versions of the file by specifying their versions ID in the GET request


<br><br><br>

## S3 MFA Deletion
- `arn:aws:iam::123456789:mda/root-ccount-mfa-device 123456`
- **MFA Delete**<br>A valid code from your MFA device is required to permanently delete an S3 object
- **S3 Versioning**<br>A valid code from your MFA device is required to suspend(or reactivate) S3 versioning
- **Protect Your Data...**<br>...against accidental or malicious deletions of your version-controlled S3 buckets.


<br><br><br>

## S3 Encryption
- **Encryption in Transit**
  - SSL/TLS
  - HTTPS
- **Server-Side Encryption at Rest:**
  - SSE-S3 (AES 256-bit)
  - SSE-KMS
  - SSE-C
- **Client-Side Encryption**
  - You encrypt the files yourself before you upload them into S3

> **SSE-S3** enabled by default

<br>

## S3 Static website hosting
S3 static web hosting is an easy and cost-effective way to host static web content

1. **Bucket Properties**<br>Enable static web hosting in your bucket properties
2. **Enable Public Access**<br>Disable **Block Public Access** settings
3. **Bucket Policy**<br>Allow public read access for your objects (`index.html`)

<br>

## S3 Presigned URL
- You can use a presigned URL to provide temporary access to S3 objects that are private. 
- Anyone with the presigned URL will be able to access the object.
- **CLI, SDK, or Console**<br>Create a presigned URL using the AWS CLI, SDK, or the AWS Console.
- **EXPIRY**<br>You can set an expiry on the URL, after which it will no longer be valid.
- **ACCESS**<br>When you share the URL, anyone who has the URL can use it until it expires.

<br><br>

## S3 Inventory
- **Inventory Report**<br>Used to help you understand how you are storing objects in an S3 bucket.
- **Supported File Formats**<br>CSV (comma- separated values), Apache ORC (Optimized Row Columnar), and Apache Parquet.
- **Example Use Cases**
    - Which objects are encrypted?
    - Which classes of storage am I using?
    - Which objects successfully replicated?
- **Stored in S3**<br>The resulting report is stored in S3, and can be encrypted using SSE-S3 or SSE-KMS.

<br><br><br>

## EFS
- **Managed NFS File System**<br>
Highly available, scalable shared file system for Linux-based workloads.
- **Multiple EC2 Instances**<br>
Great for applications which need to access shared files, e.g. a shared configuration file or state information. You cannot do this with EBS.
- **Lifecycle Management**<br>
Files which have not been accessed recently get moved to EFS Infrequent Access.
- **Encryption**<br>
In transit and at rest. You must enable it at creation; you cannot enable it later.

<br>

### EFS Throughput Modes
- A single EFS fiel system can supprot many thousands of simultaneous connections
- **Default - Burstable Throughput**<br>Throughput is determined by the **amount** of storage you have
- **Minimum 100 MiB/s**<br>All file systems get a **minimum of 100 MiB/s** of burstable throughput
- **100 MiB/s per TiB**<br>Standard class file systems **greater than 1 TiB** in size can burst to 100 MiB/s per TiB of data stored
- If you want to optimize performance for your application, use **Provisioned Throughput**, which allows you to define your throughput capability in MiB/s based on your requirements.
- **Rule of thumb**, if you need more throughput than you are getting with bursting throughput mode, switch to provisioned throughput.

<br>

### EFS and Multi-AZ Applications
- **Working with Multiple AZs**<br>For EFS Standard (which includes multi-AZ resilience), you can create a mount target in each Available Zone in an AWS Region.
- **Multiple Mounts Targets**<br>Preferable because this avoids additional data access charges for hosts located in a different AZ.
- **Increased Availability**<br>If there is a problem with the mount target in one AZ, the instances in the other AZ will be unaffected.

<br><br><br>

## Athena
1. **Interactive Query**<br>Athena is an interactive query service.
2. **Standard SQL**<br>Allows you to query data stored in S3 using standard SQL.
3. **Serverless**<br>You don't need to configure any infrastructure to use Athena.

<br>

**Configuration**:
- Point Athena to the data you want to query in S3
- Define a table schema
- Query your data using standard SQL
  
<br><br><br>

## OpenSearch
- **OpenSearch** is a fully managed **Elasticsearch** cluster based on open-source Elasticsearch technology.
- **Compatibility**:
  - Fully compatible with **Elasticsearch open-source APIs**.
  - Works with industry-standard tools like **Logstash** and **Kibana**.
- **Integration with AWS Services**:
  - Ingest data directly from **CloudWatch Logs** and **Kinesis Data Firehose**.
  - Use a **Lambda function** to ingest data from **S3** or **DynamoDB**.
- **Use Cases**:
  - Ideal for **real-time analytics**, including:
    - Log analytics
    - Application monitoring data
    - Security analytics
    - Complex business data analytics.

### OpenSearch Deployment Best Practice
1. **3 Dedicated Master Nodes**<br>Offload cluster management tasks like health checks and maintain routing and cluster state
2. **Data Nodes Deployed in Multiples of 3**<br>Store the data in shards and perform searches, query requests, and CRUD operations
3. **Deploy Across 3 AZs**<br>Distribute the data nodes across 3 AZs for the highest availability

> Public or Private?
>
> When we first create OpenSearch Domain Cluster, we either make cluster public or private to our own VPC.
> **You cannot change this configuration later**


