# CHAPTER 5<br>Reliability and Business Continuity

### Chapter Outline
- Section Introduction
- Elasticity and Scalability 101
- Introducing AWS Auto Scaling
- `Demo` Creating Auto Scaling Plans
- Troubleshooting Auto Scaling Issues
- Vertical Scaling vs. Horizontal Scaling
- Using AWS ElastiCache
- Aurora 101
- `HANDS-ON LAB` Creating an Amazon Aurora RDS Database (MySQL Compatible)
- Understanding Aurora Auto Scaling Options
- RDS and Multi-AZ Failover
- RDS and Read Replicas
- `HANDS-ON LAB` Deploy an Amazon RDS Multi-AZ and Read Replica in AWS
- `Demo` Creating and Encrypting RDS Snapshots
- Differentiating Single Availability Zones vs. Multi-AZ Deployments
- Implementing Fault Tolerant Workloads Using Amazon Elastic File System (EFS)
- Building Fault Tolerance Using Elastic IPs
- Readying for Disaster Recovery
- AWS Service Maintenance Windows
- Configuring S3 Cross-Region Replication
- Implementing Loosely Coupled Architectures with SQS
- `Demo` Automating EBS Snapshots Using Data Lifecycle Manager
- Using DynamoDB Streams for Backing Up Your Table to Another Region

<br><br><br>

## Section Introduction
- Elasticity and Scalability
- Auto Scaling in AWS
- Horizontal and Vertical Scaling
- ElastiCache
- RDS
- High Availability
- Fault Tolerance and Disaster Recovery

<br><br>

## Elasticity and Scalability 101
### What is Elasticity?
- Stretching and retracting your infrastructure based on demand(**Short term**)
- Allow you to **pay as you go**
- Typically used during a short period of time, hours or days

### What is Scalability?
- Building your infrastructure to meet your demands over **longer time**

### AWS Services: ELasticity vs Scalability
||**Elasticity**|**Scalability**|
|---|---|---|
|**EC2**|Configure Auto Scaling to increase and decrease the number of EC2 instance|Increase instance sizes<br>Use Reserved instances|
|**DynamoDB**|Increase/decrease IOPS based on traffic spikes|Unlimited amount of storage|
|**RDS**|Can't scale on demand|Increase instance size<br>Add number of instances|
|**Amazon Aurora**|Autoscale up or down to meet varying demand on the database|Modify the instance type|

<br><br><br>

## Introducing AWS Auto Scaling

> ![Youtube tutorial](https://www.youtube.com/watch?v=xQeGrgQJJDc&t=227s)

### What is AWS Auto Scaling?
An AWS Service which allows you to configure pland to automatically scale your resources
- EC2 Auto Scaling launches and terminates instances dynamically
- Scaling is horizontal (scales out)
- Provides elasticity and scalability
- Responds to EC2 status checks and CloudWatch metrics
- Can Scale based on demand (performance) or on a schedule
- Auto scaling group definescollection of EC2 instances that are scaled and managed together

### Understanding Scaling Plans
- **Scaling Plans**<br>A set of directions for scaling your resources.
- **Scaling Strategy** (within scaling plan)<br>Instructs AWS Auto Scaling on how to optimize resources in your scaling plan for availability, cost or both.
- There are three types of scaling available:
    - **Dynamic Scaling** - automatically scales based on demand
    - **Predictive Scaling** - uses Machine Learning to predict
    - **Scheduled** - scales based on a schedule

### Creating Scaling Plans
- **Cloud Formation Scripting**<br>**Find scalable resources** through existing CloudFormation templates
- **EC2 Auto Scaling Group**<br>**Select one or more** existing EC2 Auto Scaling groups to be included in your scaling plans
- **Tagged Resources**<br>**Search for scalable resources** using the tags applied to them


### Scalable AWS Services
|Service|Description|
|---|---|
|**EC2**|Maintain an Auto Scaling group through launching or terminating instances|
|**DynamoDB**|Enable tables or secondary indexes to increase or decrease read and write capacity|
|**Elastic Container Services**|Adjust ECS service count up/down|
|**Aurora**|Automatically adjust the number of read replicas in the Aurora DB cluster|

### Health Checks
- EC2 = EC2 status checks
- ELB = Uses the ELB health checks in addition to EC2 status checks
  
### Health check grace period
- How long to wait before checking the health status of the instance
- Auto Scaling does not act on health checks until grace period expires

### Types of policies
- **Target tracking scaling** - Increase and decrease the current capacity of the group based on an Amazon Cloud Watch metric and a target value. E.g., keeping the aggregate CPU usage of your ASG at 70%
- **Step scaling** - Increase and decrease the current capacity of the group based on a set of scaling adjustments, known as step adjustments, that vary based on the size of the alarm breach
- **Simple scaling** - Increase and decrease the current capacity of the group based on a single scaling adjustment, with cooldown period between each scaling activity

### Auto Scaling - Monitoring
#### Group metrics (ASG)
- Data points about the Auto Scaling group
- 1-minute granularity
- No charge
- Must be enabled
#### Basic monitoring (Instances)
- 5-minute granularity
- No Charge
#### Detailed monitoring (Instances)
- 1-minute granularity
- Charges apply


### Additional Scaling Settings
- **Cooldowns** - Used with simple scaling policy to prevent Auto Scaling from launching or terminating before effects of previous activities are visible. Default value is 300 seconds (5 minutes)
- **Termination Policy** - Controls which instances to terminate first when a scale-in event occurs 
- **Termination Protection** - Prevents Auto Scaling from terminating protected instances
- **Standby State** - Used to put an instance in the InService state into the Standby state, update or troubleshoot the instance
- **Lifecycle Hooks** Used to perform custom actions by pausing instances as the ASG launches or terminates them
- Use case:
    - Run a script to download and install software after launching
    - Pause an instance to process data before a scale-in (termination)

<br><br><br>

## Trhoubleshooting Auto Scaling Issues
### Common Issues with Auto Scaling
1. Auto Scaling Group not found
2. Auto Scaling Service not enabled in your account (common with accounts enrolled within AWS Organization or may have active service control policies preventing you from the use of the service)
3. Auto Scaling config not working correctly

### Compute/Storage Issues
1. Invalid EBS device mapping
2. Instance type not compatible in AZ
3. Attempting to attach an EBS block device to an instance-store AMI
4. AZ no longer supported

### Security Issues
1. Associated key pair does not exist
2. Security group does not exist

<br><br><br>

## Vertical vs Horizontal Scaling
### Vertical vs. Horizontal Scaling: Real-World Analogy
- Imagine planning a trip with friends:
  - **Vertical Scaling**: Booking a larger house to accommodate everyone. In computing, this equates to upgrading a machine’s capacity to handle increased demand.
  - **Horizontal Scaling**: Booking multiple houses to share the group. This method distributes the load across several instances, balancing demand.

### Vertical Scaling
- Involves increasing the capacity of a single system to handle greater load.
- Technical resources that might be upgraded include **CPU, memory, storage, and disk I/O**.
- **Example with AWS EC2**: To vertically scale, increase the instance size, adding more compute power to a single EC2 instance.
- **Example with AWS RDS**: Increase the database instance size to provide more processing capacity.

### Horizontal Scaling
- Entails adding multiple systems or instances to share the load.
- Implements **load balancing**, **Auto Scaling groups**, and **multi-availability zones** to manage demand.
- **Example with AWS EC2**: Horizontally scale by configuring an Auto Scaling group to add instances as demand increases.
- **Example with AWS RDS**: Implement read replicas to share read traffic, enhancing overall system performance.

### AWS Service Application
- **EC2**:
  - *Vertical Scaling*: Increase instance size.
  - *Horizontal Scaling*: Configure Auto Scaling groups to add instances dynamically.
- **RDS**:
  - *Vertical Scaling*: Increase the database instance size.
  - *Horizontal Scaling*: Create read replicas for distributing read traffic.


<br><br><br>

## Using AWS ElastiCache
### **What is AWS ElastiCache?**
   - **Definition**<br>AWS ElastiCache is a managed caching service that allows users to deploy, scale, and manage in-memory data caches in the cloud, facilitating quick access to the most frequently requested data.
   - **Purpose**<br>ElastiCache improves performance by storing critical, frequently accessed data in-memory, reducing the load on databases and enhancing response times.

<br>

### **Understanding Caching**
   - **Example**<br>Similar to a barista quickly answering frequently asked questions, caching serves commonly accessed data without needing to query the database each time.
   - **Cache Hit**<br>When data is found in ElastiCache, it’s quickly returned to the application.
   - **Cache Miss**<br>If data is not found in ElastiCache, the application retrieves it from a database (e.g., RDS), adding latency.

<br>

### **Benefits of Using ElastiCache**
   - **Improved Latency and Throughput**<br>Ideal for read-heavy applications like social networking, gaming, and media sharing.
   - **Enhanced Application Performance**<br>Stores critical data in memory, speeding up data retrieval for I/O-intensive queries and computationally heavy processes (e.g., machine learning models).

<br>

### **Types of ElastiCache Engines**
   - `Memcached`
     - Multithreaded and suitable for distributed caching.
     - Does not support snapshots or replication.
   - **Redis**:
     - Supports advanced data structures, snapshots, and replication, but no multithreading is available.
     - Offers more functionality for applications requiring persistent storage.
   - Both engines support **data partitioning** and **sub-millisecond latency**.

<br>

### **Launching ElastiCache**
   - **Configuration Steps**:
     1. Select the cache engine (Redis or Memcached) and define cluster settings.
     2. Configure node type and replica count.
     3. Set up multi-AZ deployment if needed and configure security groups.
     4. Enable inbound traffic, connect to the cluster, and load data.

<br>

### **Monitoring ElastiCache**
   - **Key Metrics**:
     - **CPU Utilization**: If CPU usage exceeds thresholds, consider scaling out with additional nodes.
     - **Swap Usage**: If swap usage surpasses 50 MB, allocate more memory.
     - **Evictions**: Address cache evictions by adding nodes or increasing node size.
     - **Concurrent Connections**: High connection counts may indicate issues with application access to the cache.

<br><br><br>



